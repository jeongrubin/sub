{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfVoZc61s4zVe1TKAqG8++",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeongrubin/sub/blob/main/06_01_PDFLoader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PDF Loader"
      ],
      "metadata": {
        "id": "bcphPlFfwZax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N3f62ZXbwY4b"
      },
      "outputs": [],
      "source": [
        "FILE_PATH = \"SPRI_AI_Brief_2023년12월호_F.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_metadata(docs):\n",
        "    if docs:\n",
        "        print(\"[metadata]\")\n",
        "        print(list(docs[0].metadata.keys()))\n",
        "        print(\"\\n[examples]\")\n",
        "        max_key_length = max(len(k) for k in docs[0].metadata.keys())\n",
        "        for k, v in docs[0].metadata.items():\n",
        "            print(f\"{k:<{max_key_length}} : {v}\")"
      ],
      "metadata": {
        "id": "Pw6GPWRfw6eh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.pypdf"
      ],
      "metadata": {
        "id": "hcF-q_Obxy6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# 파일 경로 설정\n",
        "loader = PyPDFLoader(FILE_PATH)\n",
        "\n",
        "# PDF 로더 초기화\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "R9H81CiEw6i4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서의 내용 출력\n",
        "print(docs[10].page_content[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta9a5tzfw6lL",
        "outputId": "526aa206-e5f8-4b09-cc3f-844229c21751"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPRi AI Brief |  2023-12월호\n",
            "8\n",
            "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개n코히어와 12개 기관이  광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, 작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시n대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 구성과 계보도 추적 가능\n",
            "KEY Contents\n",
            "£데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상nAI 기업 코히어(Cohere)가 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 메타데이터 출력\n",
        "show_metadata(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXgJXhWRw6nQ",
        "outputId": "29fbb73b-5a24-4776-e85e-871c46d61fd3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[metadata]\n",
            "['source', 'page']\n",
            "\n",
            "[examples]\n",
            "source : SPRI_AI_Brief_2023년12월호_F.pdf\n",
            "page   : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.pymupdf"
      ],
      "metadata": {
        "id": "kaxBrvFqzcet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 설치\n",
        "!pip install -qU pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ezNqTVRw6pI",
        "outputId": "b0852d82-65c7-4e3a-a6d8-c70cfccc77eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "# PyMuPDF 로더 인스턴스 생성\n",
        "loader = PyMuPDFLoader(FILE_PATH)\n",
        "\n",
        "# 문서 로드\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "mET819sAzjXj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[10].page_content[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4Jx6tayzlIg",
        "outputId": "a285cf2c-3556-494f-a151-adde296ccbd2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPRi AI Brief |  \n",
            "2023-12월호\n",
            "8\n",
            "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
            "n 코히어와 12개 기관이  광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, \n",
            "작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시\n",
            "n 대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \n",
            "구성과 계보도 추적 가능\n",
            "KEY Contents\n",
            "£ 데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
            "n AI 기업 코히어\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_metadata(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THmOShF9zyf_",
        "outputId": "8d2f0ceb-6e31-4d69-c4bb-d0927480c9c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[metadata]\n",
            "['source', 'file_path', 'page', 'total_pages', 'format', 'title', 'author', 'subject', 'keywords', 'creator', 'producer', 'creationDate', 'modDate', 'trapped']\n",
            "\n",
            "[examples]\n",
            "source       : SPRI_AI_Brief_2023년12월호_F.pdf\n",
            "file_path    : SPRI_AI_Brief_2023년12월호_F.pdf\n",
            "page         : 0\n",
            "total_pages  : 23\n",
            "format       : PDF 1.4\n",
            "title        : \n",
            "author       : dj\n",
            "subject      : \n",
            "keywords     : \n",
            "creator      : Hwp 2018 10.0.0.13462\n",
            "producer     : Hancom PDF 1.3.0.542\n",
            "creationDate : D:20231208132838+09'00'\n",
            "modDate      : D:20231208132838+09'00'\n",
            "trapped      : \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyPDFium2"
      ],
      "metadata": {
        "id": "PAXgiyoE0w_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypdfium2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfs17_RZ02Gc",
        "outputId": "2a3f2216-cd2e-4bc4-dabd-b5541bf62c5b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdfium2\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.9 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2\n",
            "Successfully installed pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFium2Loader\n",
        "\n",
        "# PyPDFium2 로더 인스턴스 생성\n",
        "loader = PyPDFium2Loader(FILE_PATH)\n",
        "\n",
        "# 데이터 로드\n",
        "docs = loader.load()\n",
        "\n",
        "# 문서의 내용 출력\n",
        "print(docs[10].page_content[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqlmi7dW0zVD",
        "outputId": "2e67a37c-84f1-47dc-8590-bcf4ee5392aa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPRi AI Brief | \r\n",
            "2023-12월호\r\n",
            "8\r\n",
            "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\r\n",
            "n 코히어와 12개 기관이 광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, 작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시\r\n",
            "n 대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \r\n",
            "구성과 계보도 추적 가능\r\n",
            "KEY Contents\r\n",
            "£ 데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\r\n",
            "n AI \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pypdfium2/_helpers/textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
            "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_metadata(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-7_wLjE04u4",
        "outputId": "ae42e63f-6ffa-49e3-d88b-05da769c578f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[metadata]\n",
            "['source', 'page']\n",
            "\n",
            "[examples]\n",
            "source : SPRI_AI_Brief_2023년12월호_F.pdf\n",
            "page   : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PDFMiner"
      ],
      "metadata": {
        "id": "W0jBYqfYrVn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc8HmWDhrdv_",
        "outputId": "c8167ba2-ed08-4828-b62b-4b835c324380"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.13 (from langchain_community)\n",
            "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.27 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain_community) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain_community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain_community) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.13 langchain-core-0.3.28 langchain_community-0.3.13 marshmallow-3.23.2 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfminer.six"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmrEz6tWrwm1",
        "outputId": "55ead197-2c34-42c8-f8b0-d9f0e0043e02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20240706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PDFMinerLoader\n",
        "\n",
        "# PDFMiner 로더 인스턴스 생성\n",
        "loader = PDFMinerLoader(FILE_PATH)\n",
        "\n",
        "# 데이터 로드\n",
        "docs = loader.load()\n",
        "\n",
        "# 문서의 내용 출력\n",
        "print(docs[0].page_content[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSGaO85T0zYE",
        "outputId": "52ac29c8-2a90-4b75-8e2f-ba1385856fd8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023년  12월호\n",
            "\n",
            "\f2023년  12월호\n",
            "\n",
            "Ⅰ.  인공지능  산업  동향  브리프\n",
            "\n",
            "  1.  정책/법제 \n",
            "\n",
            "      ▹  미국,  안전하고  신뢰할  수  있는  AI  개발과  사용에  관한  행정명령  발표    ························· 1\n",
            "\n",
            "      ▹  G7,  히로시마  AI  프로세스를  통해  AI  기업  대상  국제  행동강령에  합의 ··························· 2\n",
            "\n",
            "      ▹  영국  AI  안전성  정상회의에  참가한  28개국,  AI  위험에  공동 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_metadata(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ncLPxqF0zab",
        "outputId": "f55041a4-214f-499c-83d2-4850a8eaebd8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[metadata]\n",
            "['source']\n",
            "\n",
            "[examples]\n",
            "source : SPRI_AI_Brief_2023년12월호_F.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PDFMinerPDFasHTMLLoader\n",
        "\n",
        "# PDFMinerPDFasHTMLLoader 인스턴스 생성\n",
        "loader = PDFMinerPDFasHTMLLoader(FILE_PATH)\n",
        "\n",
        "# 문서 로드\n",
        "docs = loader.load()\n",
        "\n",
        "# 문서의 내용 출력\n",
        "print(docs[0].page_content[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXsoaA20tfCj",
        "outputId": "d220f70b-2526-4f97-ed8c-c6a5f996f5df"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html><head>\n",
            "<meta http-equiv=\"Content-Type\" content=\"text/html\">\n",
            "</head><body>\n",
            "<span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span>\n",
            "<div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div>\n",
            "<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:256px; top:332px; width:98px; height:20px;\"><span style=\"font-family: KoPubDotumBold; font-size:14px\">2023년  </span><span style=\"font-family: KoPubDotumBold; font-size:20px\">12</span><span style=\"font-family: KoPubDotumBold; font-size:14px\">월호\n",
            "<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:0px; top:50px; width:612px; height:858px;\"></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:958px; width:612px; height:858px;\"></span>\n",
            "<div style=\"position:absolute; top:958px;\"><a name=\"2\">Page 2</a></div>\n",
            "<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_metadata(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6YwJDa5tf9r",
        "outputId": "e3432263-e52e-4e8d-e978-bc1e6bf95a42"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[metadata]\n",
            "['source']\n",
            "\n",
            "[examples]\n",
            "source : SPRI_AI_Brief_2023년12월호_F.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(docs[0].page_content, \"html.parser\")  # HTML 파서 초기화\n",
        "content = soup.find_all(\"div\")  # 모든 div 태그 검색"
      ],
      "metadata": {
        "id": "LLdQftUItgAL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cur_fs = None\n",
        "cur_text = \"\"\n",
        "snippets = []  # 동일한 글꼴 크기의 모든 스니펫 수집\n",
        "for c in content:\n",
        "    sp = c.find(\"span\")\n",
        "    if not sp:\n",
        "        continue\n",
        "    st = sp.get(\"style\")\n",
        "    if not st:\n",
        "        continue\n",
        "    fs = re.findall(\"font-size:(\\d+)px\", st)\n",
        "    if not fs:\n",
        "        continue\n",
        "    fs = int(fs[0])\n",
        "    if not cur_fs:\n",
        "        cur_fs = fs\n",
        "    if fs == cur_fs:\n",
        "        cur_text += c.text\n",
        "    else:\n",
        "        snippets.append((cur_text, cur_fs))\n",
        "        cur_fs = fs\n",
        "        cur_text = c.text\n",
        "snippets.append((cur_text, cur_fs))\n",
        "# 중복 스니펫 제거 전략 추가 가능성 (PDF의 헤더/푸터가 여러 페이지에 걸쳐 나타나므로 중복 발견 시 중복 정보로 간주 가능)"
      ],
      "metadata": {
        "id": "XuCqGyqrtgCs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "cur_idx = -1\n",
        "semantic_snippets = []\n",
        "# 제목 가정: 높은 글꼴 크기\n",
        "for s in snippets:\n",
        "    # 새 제목 판별: 현재 스니펫 글꼴 > 이전 제목 글꼴\n",
        "    if (\n",
        "        not semantic_snippets\n",
        "        or s[1] > semantic_snippets[cur_idx].metadata[\"heading_font\"]\n",
        "    ):\n",
        "        metadata = {\"heading\": s[0], \"content_font\": 0, \"heading_font\": s[1]}\n",
        "        metadata.update(docs[0].metadata)\n",
        "        semantic_snippets.append(Document(page_content=\"\", metadata=metadata))\n",
        "        cur_idx += 1\n",
        "        continue\n",
        "\n",
        "    # 동일 섹션 내용 판별: 현재 스니펫 글꼴 <= 이전 내용 글꼴\n",
        "    if (\n",
        "        not semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
        "        or s[1] <= semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
        "    ):\n",
        "        semantic_snippets[cur_idx].page_content += s[0]\n",
        "        semantic_snippets[cur_idx].metadata[\"content_font\"] = max(\n",
        "            s[1], semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
        "        )\n",
        "        continue\n",
        "\n",
        "    # 새 섹션 생성 조건: 현재 스니펫 글꼴 > 이전 내용 글꼴, 이전 제목 글꼴 미만\n",
        "    metadata = {\"heading\": s[0], \"content_font\": 0, \"heading_font\": s[1]}\n",
        "    metadata.update(docs[0].metadata)\n",
        "    semantic_snippets.append(Document(page_content=\"\", metadata=metadata))\n",
        "    cur_idx += 1\n",
        "\n",
        "print(semantic_snippets[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV7ajRwptmMv",
        "outputId": "51357de3-3775-44d0-ffc1-7048b1b1797f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='KEY Contents\n",
            "n 미국 바이든 대통령이 ‘안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령’에 서명하고 \n",
            "광범위한  행정  조치를  명시\n",
            "n 행정명령은 △AI의 안전과 보안 기준 마련 △개인정보보호 △형평성과 시민권 향상 △소비자 \n",
            "보호  △노동자  지원  △혁신과  경쟁  촉진  △국제협력을  골자로  함\n",
            "' metadata={'heading': '미국,  안전하고  신뢰할  수  있는  AI  개발과  사용에  관한  행정명령  발표 \\n', 'content_font': 12, 'heading_font': 15, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf'}\n"
          ]
        }
      ]
    }
  ]
}